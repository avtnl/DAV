from loguru import logger
from datetime import datetime
import pytz
from file_manager import FileManager
from data_editor import DataEditor
from data_preparation import DataPreparation, InteractionSettings, NoMessageContentSettings
from plot_manager import PlotManager
import tomllib
from pathlib import Path
import scripts  # Import the scripts module

def main():
    # Available scripts are listed below:
    # 1 = categories
    # 2 = time
    # 3 = distribution
    # 4 = relationships - network
    # 5 = relationships - bubble
    # 7 = PCA/ t-SNE - interaction dynamics
    # 10 = PCA/ t-SNE - author fingerprints without actual text within messages | adding and removing features to dataframe
    # 11 = PCA/ t-SNE - visualization of features in dataframe generated by script 10

    # Assign Scripts to run (Script0 already executed), reordered to prioritize Script7
    SCRIPTS = [7,1,2,3,4,5,10,11]  # Enforce desired order: 7 first, then 1-5

    # Instantiate classes
    file_manager = FileManager()
    data_editor = DataEditor()
    data_preparation = DataPreparation(
        data_editor=data_editor,
        int_settings=InteractionSettings(),
        nmc_settings=NoMessageContentSettings(),
    )
    plot_manager = PlotManager()

    # Configure loguru to create a timestamped log file
    log_dir = Path("logs")  # Adjust to your preferred log directory
    log_dir.mkdir(exist_ok=True)  # Create logs directory if it doesn't exist
    timestamp = datetime.now(tz=pytz.timezone('Europe/Amsterdam')).strftime("%Y%m%d-%H%M%S")
    log_file = log_dir / f"logfile-{timestamp}.log"
    logger.add(log_file, rotation=None, retention=None, level="DEBUG")  # Add timestamped log file

    # Remove any existing handlers that write to a static logfile.log (if necessary)
    logger.remove()  # Remove default stderr handler if you don't want console output
    logger.add(log_file, rotation=None, retention=None, level="DEBUG")  # Ensure only the timestamped file is used

    # Load config for preprocess flag and image directory
    configfile = Path("config.toml").resolve()
    with configfile.open("rb") as f:
        config = tomllib.load(f)
    image_dir = Path(config["image"])
    processed = Path(config["processed"])  # Extract processed dir from config

    # Execute preprocessing pipeline via Script0
    preprocess_script = scripts.Script0(
        file_manager, data_editor, data_preparation, processed, config, image_dir
    )
    result = preprocess_script.run()
    
    if result is None:
        logger.error("Preprocessing failed. Exiting.")
        return
    
    # Extract results from preprocessing
    df = result['df']
    tables_dir = result['tables_dir']
    dataframes = result['dataframes']

    # Debug: Log the shape of the preprocessed DataFrame
    logger.debug(f"Preprocessed df shape: {df.shape}")

    # Check if Scripts need category data
    scripts_needing_categories = [1, 4, 5, 7]  # Scripts that need category data
    group_authors, non_anthony_group, anthony_group, sorted_groups = None, None, None, None
    if any(script in SCRIPTS for script in scripts_needing_categories):
        original_df = df  # Save original df
        df, group_authors, non_anthony_group, anthony_group, sorted_groups = scripts.prepare_category_data(
            data_preparation, df, logger
        )
        if df is None or group_authors is None or sorted_groups is None:
            logger.error("Failed to initialize required variables for Scripts 1, 4, 5, or 7.")
            return

    # Initialize script_list with all relevant scripts
    script_list = {}
    if group_authors is not None:  # Only add category-dependent scripts if data is prepared
        script_list.update({
            1: scripts.Script1(file_manager, plot_manager, image_dir, group_authors, non_anthony_group, anthony_group, sorted_groups),
            4: scripts.Script4(file_manager, data_preparation, plot_manager, image_dir, tables_dir, group_authors, original_df),  # Pass original df
            5: scripts.Script5(file_manager, data_preparation, plot_manager, image_dir, df),
            7: scripts.Script7(file_manager, data_preparation, plot_manager, image_dir, group_authors, original_df),  # Pass original df
        })
    script_list.update({  # Always include scripts not needing category data
        2: scripts.Script2(file_manager, data_preparation, plot_manager, image_dir, df),
        3: scripts.Script3(file_manager, data_editor, data_preparation, plot_manager, image_dir, df),
        10: scripts.Script10(file_manager, data_editor, data_preparation, processed, tables_dir),
        11: scripts.Script11(file_manager, data_editor, data_preparation, plot_manager, processed, image_dir),
    })

    # Execute scripts based on script list
    for script_id in SCRIPTS:
        if script_id in script_list:
            script_list[script_id].run()
        else:
            logger.warning(f"Unknown script {script_id} in Script list. Skipping.")

if __name__ == "__main__":
    main()