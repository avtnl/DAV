import pandas as pd
import numpy as np
from loguru import logger
from file_manager import FileManager
from data_editor import DataEditor
from data_preparation import DataPreparation, SequenceSettings, InteractionSettings, NonMessageContentSettings
from plot_manager import PlotManager, PlotSettings, CategoriesPlotSettings, TimePlotSettings, DistributionPlotSettings, NonMessageContentSettings as PMNonMessageContentSettings, DimensionalityReductionSettings
import tomllib
from pathlib import Path
import scripts  # Import the scripts module

def main():
    # Instantiate classes
    file_manager = FileManager()
    data_editor = DataEditor()
    data_preparation = DataPreparation(
        data_editor=data_editor,
        seq_settings=SequenceSettings(),
        int_settings=InteractionSettings(),
        nmc_settings=NonMessageContentSettings(),
    )
    plot_manager = PlotManager()

    # Assign Scripts to run
    # 1 = categories
    # 2 = time
    # 3 = distribution
    # 4 = relationships - network
    # 5 = relationships - bubble
    # 7 = PCA/ t-SNE - interaction dynamics
    # 10 = PCA/ t-SNE - author fingerprints without actual text within messages | adding and removing features to dataframe
    # 11 = PCA/ t-SNE - visualization of features in dataframe generated by script 10
    Script = [10, 11]

    # Get CSV file(s), processed directory, group mapping, and Parquet files
    datafiles, processed, group_map, parq_files = file_manager.read_csv()

    # Check if any datafiles were returned
    if not datafiles or datafiles is None:
        logger.error("No valid data files were loaded. Exiting.")
        return

    # Initialize dataframes dictionary
    dataframes = {}

    # Load config for preprocess flag and image directory
    configfile = Path("config.toml").resolve()
    with configfile.open("rb") as f:
        config = tomllib.load(f)
    image_dir = Path(config["image"])

    # Process files
    if config["preprocess"]:
        for datafile in datafiles:
            if not datafile.exists():
                logger.warning(f"{datafile} does not exist. Maybe check timestamp!")
                continue
            try:
                df = data_editor.convert_timestamp(datafile)
                df = data_editor.clean_author(df)
                df["has_emoji"] = df["message"].apply(data_editor.has_emoji)
                for key, parq_name in parq_files.items():
                    if parq_name.replace(".parq", ".csv") == datafile.name:
                        df["whatsapp_group"] = group_map[key]
                        break
                else:
                    df["whatsapp_group"] = "unknown"
                logger.info(f"Processed DataFrame from {datafile}:\n{df.head()}")

                csv_file = file_manager.save_csv(df, processed)
                parq_file = file_manager.save_parq(df, processed)
                logger.info(f"Saved files: CSV={csv_file}, Parquet={parq_file}")

                dataframes[datafile.stem] = df
            except Exception as e:
                logger.error(f"Failed to process {datafile}: {e}")
                continue
    else:
        for key, group in group_map.items():
            datafile = processed / config[key]
            datafile = datafile.with_suffix(".csv")
            logger.debug(f"Attempting to load {datafile}")
            if not datafile.exists():
                logger.warning(f"{datafile} does not exist. Run preprocess.py or check timestamp!")
                continue
            try:
                df = data_editor.convert_timestamp(datafile)
                df = data_editor.clean_author(df)
                df["has_emoji"] = df["message"].apply(data_editor.has_emoji)
                df["whatsapp_group"] = group
                dataframes[key] = df
                logger.info(f"Loaded {datafile} with {len(df)} rows")
            except Exception as e:
                logger.exception(f"Failed to load {datafile}: {e}")
                continue

    if not dataframes:
        logger.error("No valid data files were loaded. Exiting.")
        return

    df = data_editor.concatenate_df(dataframes)
    if df is None:
        return
    df = data_editor.filter_group_names(df)
    if df is None:
        return

    df = data_editor.clean_for_deleted_media_patterns(df)
    if df is None:
        logger.error("Failed to clean messages for all groups.")
        return

    csv_file, parq_file = file_manager.save_combined_files(df, processed)
    if csv_file is None or parq_file is None:
        return
    df = data_editor.filter_group_names(df)
    if df is None:
        return

    tables_dir = Path("tables")
    tables_dir.mkdir(parents=True, exist_ok=True)

    # Prepare common variables for steps
    group_authors, non_anthony_group, anthony_group, sorted_groups = None, None, None, None
    if any(step in Script for step in [1, 4, 5, 7, 8]):
        df, group_authors, non_anthony_group, anthony_group, sorted_groups = data_preparation.build_visual_categories(df)
        if df is None or group_authors is None or sorted_groups is None:
            logger.error("Failed to initialize required variables for STEPs 1, 4, 5, 7 or 8.")
            return

    # Execute steps based on Script list
    steps = {
        1: scripts.Step1Script(file_manager, plot_manager, image_dir, group_authors, non_anthony_group, anthony_group, sorted_groups),
        2: scripts.Step2Script(file_manager, data_preparation, plot_manager, image_dir, df),
        3: scripts.Step3Script(file_manager, data_editor, data_preparation, plot_manager, image_dir, df),
        4: scripts.Step4Script(file_manager, data_preparation, plot_manager, image_dir, tables_dir, group_authors),
        5: scripts.Step5Script(file_manager, data_preparation, plot_manager, image_dir, df),
        7: scripts.Step7Script(file_manager, data_preparation, plot_manager, image_dir, group_authors),
        10: scripts.Step10Script(file_manager, data_editor, data_preparation, processed, tables_dir),
        11: scripts.Step11Script(file_manager, data_editor, data_preparation, plot_manager, processed, image_dir)
    }
    for step in Script:
        if step in steps:
            steps[step].run()
        else:
            logger.warning(f"Unknown step {step} in Script list. Skipping.")

if __name__ == "__main__":
    main()